{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "from tqdm import trange\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_frequencies(dirpath):\n",
    "    \n",
    "    dirpath = os.walk(dirpath)\n",
    "    df_all = pd.DataFrame()\n",
    "    name_files = []\n",
    "    print(\"Reading files...\")\n",
    "    for dirpath, dirnames, filenames in dirpath:\n",
    "        for filename in [f for f in filenames if f.endswith(\".freq\")]:\n",
    "            path_freq_file = os.path.join(dirpath, filename)             \n",
    "            name_freq_file = path_freq_file.split('/')[-1]                  \n",
    "            name_files.append(name_freq_file)\n",
    "            df_cpgs_file = pd.read_table(path_freq_file, sep=\"\\t\", index_col=\"position\" )                                                            \n",
    "            df_all = df_all.append(df_cpgs_file.T)                                                         \n",
    "    df_all = df_all.fillna(0)\n",
    "    df_all = df_all.T            \n",
    "    print(\"Preprocessing dataframe...\")\n",
    "    print(len(name_files))\n",
    "    X_train = preprocess_df(df_all, name_files)    \n",
    "    print(\"Preprocessing Done!\")\n",
    "    \n",
    "    return X_train, name_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_df(df_pos):\n",
    "    df = pd.DataFrame()\n",
    "    ### transoforms each sample to the sample scale row/all\n",
    "    for i in range(len(df_pos)):\n",
    "        row = df_pos.iloc[i]\n",
    "        row = row/sum(row)\n",
    "        df = df.append(pd.DataFrame(np.array(row).reshape(1,6), columns = df_pos.columns))\n",
    "    df = df.fillna(0)\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(df)\n",
    "    df_transformed = scaler.transform(df)    \n",
    "    df_transformed = pd.DataFrame(df_transformed, columns=df_pos.columns, index=df_pos.index)\n",
    "\n",
    "    return df_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_df(df_all, name_files):\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    for index in range(len(df_all)):        \n",
    "        \n",
    "        df_tmp = pd.DataFrame()\n",
    "        a = pd.DataFrame(df_all.iloc[index][\"A\"])\n",
    "        a.index=name_files\n",
    "        a.columns = [\"A\"]\n",
    "        \n",
    "        t = pd.DataFrame(df_all.iloc[index][\"T\"])    \n",
    "        t.index=name_files\n",
    "        t.columns = [\"T\"]    \n",
    "\n",
    "        g = pd.DataFrame(df_all.iloc[index][\"G\"])\n",
    "        g.index=name_files\n",
    "        g.columns = [\"G\"]\n",
    "\n",
    "        c = pd.DataFrame(df_all.iloc[index][\"C\"])\n",
    "        c.index=name_files\n",
    "        c.columns = [\"C\"]\n",
    "\n",
    "        insertion = pd.DataFrame(df_all.iloc[index][\"+\"])\n",
    "        insertion.index=name_files\n",
    "        insertion.columns = [\"+\"]\n",
    "\n",
    "        deletion = pd.DataFrame(df_all.iloc[index][\"-\"])\n",
    "        deletion.index=name_files\n",
    "        deletion.columns = [\"-\"]\n",
    "\n",
    "        df_tmp = pd.concat([df_tmp, a, t, g, c, insertion, deletion], axis=1, sort=False)                \n",
    "        df_scaled = transform_df(df_tmp)\n",
    "        \n",
    "        df = pd.concat([df, df_scaled], axis=1)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X_test, dirpath):\n",
    "    load_model = tf.keras.models.load_model\n",
    "    y_probs = np.array(0)\n",
    "    nets = 0\n",
    "    df_activations = pd.DataFrame()    \n",
    "    dirpath = os.walk(dirpath)\n",
    "    \n",
    "    for dirpath, dirnames, filenames in dirpath:\n",
    "        for filename in [f for f in filenames if f.endswith(\".model\")]:        \n",
    "            \n",
    "            nets += 1\n",
    "            print(nets)                        \n",
    "            path_model = os.path.join(dirpath, filename)             \n",
    "            name_model = path_model.split('/')[-1]                   \n",
    "            train_model = load_model(path_model)            \n",
    "            y_pred = train_model.predict_classes(X_test)\n",
    "            y_probs = y_probs + train_model.predict(X_test)            \n",
    "            \n",
    "    return y_pred,y_probs/nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X_test, dirpath):\n",
    "    \n",
    "    nets = 0\n",
    "    list_models = []\n",
    "    y_probs = np.array(0)\n",
    "    df_activations = pd.DataFrame()    \n",
    "    dirpath = os.walk(dirpath)\n",
    "    load_model = tf.keras.models.load_model        \n",
    "    \n",
    "    for dirpath, dirnames, filenames in dirpath:\n",
    "        for filename in [f for f in filenames if f.endswith(\".model\")]:   \n",
    "            path_model = os.path.join(dirpath, filename)    \n",
    "            list_models.append(path_model)\n",
    "    \n",
    "    for i in trange(len(list_models)):                                                    \n",
    "            path_model = os.path.join(dirpath, filename)             \n",
    "            name_model = path_model.split('/')[-1]                   \n",
    "            train_model = load_model(path_model)            \n",
    "            y_pred = train_model.predict_classes(X_test)\n",
    "            y_probs = y_probs + train_model.predict(X_test)                        \n",
    "            time.sleep(0.01)\n",
    "            nets += 1               \n",
    "    return y_pred,y_probs/nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_dirpath = \"freq/\" # Tissue ID\n",
    "model_dirpath = \"Model/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading files...\n",
      "Preprocessing dataframe...\n",
      "9\n",
      "Preprocessing Done!\n"
     ]
    }
   ],
   "source": [
    "X_test, name_files_test = process_frequencies(freq_dirpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [04:19<00:00,  9.69s/it]\n"
     ]
    }
   ],
   "source": [
    "y_pred, y_probs = predict(X_test.values, model_dirpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Predictions and probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_probs = pd.DataFrame(y_probs,name_files_test)\n",
    "df_probs.columns = [\"Skin\", \"Oral\",\"Vagina\"]\n",
    "df_probs.to_csv(\"predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
